# Storage Configuration
CRAWL_USE_S3=false  # Set to 'true' to enable S3 storage (optional)
CRAWL_STORAGE_PATH=./crawl_output  # Local storage path (used by default)

# AWS Configuration (optional - only required if CRAWL_USE_S3=true)
AWS_ACCESS_KEY_ID=your_access_key_here
AWS_SECRET_ACCESS_KEY=your_secret_key_here
AWS_REGION=us-east-1
S3_BUCKET=my-markdown-bucket

# LLM Configuration (optional - only needed for enhanced features)
OPENAI_API_KEY=your_openai_key_here  # Required for LLM-powered extraction
OLLAMA_BASE_URL=http://localhost:11434  # Optional - for using Ollama instead of OpenAI

# API Configuration (used by frontend)
VITE_API_URL=http://backend:8000
VITE_DEFAULT_S3_BUCKET=my-markdown-bucket

# Database Configuration
CRAWL_DB_TYPE=sqlite  # Change to 'postgres' for PostgreSQL
CRAWL_DB_HOST=localhost  # Required for PostgreSQL
CRAWL_DB_PORT=5432  # Required for PostgreSQL
CRAWL_DB_NAME=crawlai.db
CRAWL_DB_USER=postgres  # Required for PostgreSQL
CRAWL_DB_PASSWORD=your_password  # Required for PostgreSQL

# Crawler Configuration
CRAWL_MAX_DEPTH=3
CRAWL_STAY_ON_DOMAIN=true
CRAWL_FOLLOW_SUBDOMAINS=false
CRAWL_PARALLEL_DOWNLOADS=5
CRAWL_FILE_TYPES=.pdf,.doc,.docx,.xls,.xlsx,.csv

# Change Detection Settings
CRAWL_CHANGE_DETECTION=true
CRAWL_CHANGE_STRATEGY=structural
CRAWL_FORCE_REFRESH=false
